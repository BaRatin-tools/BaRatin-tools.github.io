<!DOCTYPE html>
<html lang="fr">

  <head>
    
	    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]                  
    }
  };
</script>



    

    <meta charset="utf-8">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Le B.A.-BA de l‚Äôinf√©rence Bayesienne</title>
<meta name="author" content="" />





<meta name="description" content="">

<meta name="generator" content="Hugo 0.122.0">


<link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>


<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.11.2/css/all.css">
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link href="/css/animate.css" rel="stylesheet">



  <link href="/css/style.blue.css" rel="stylesheet" id="theme-stylesheet">



<link href="/css/custom.css?1709721801" rel="stylesheet">



  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->



<link rel="shortcut icon" href="/img/logo.png" type="image/x-icon" />
<link rel="apple-touch-icon" href="/img/logo.png" />


<link rel="alternate" href="https://baratin-tools.github.io/index.xml" type="application/rss+xml" title="BaRatin - Bayesian Rating Curves">








<meta property="og:locale" content="fr">
<meta property="og:site_name" content="BaRatin - Bayesian Rating Curves">
<meta property="og:title" content="Le B.A.-BA de l‚Äôinf√©rence Bayesienne">
<meta property="og:type" content="website">
<meta property="og:url" content="https://baratin-tools.github.io/fr/doc/topics/bayesien/" />
<meta property="og:description" content="">
<meta property="og:image" content="https://baratin-tools.github.io/img/logo.png">
<meta property="og:image:type" content="image/png">



  <meta property="og:image:width" content="145">
  <meta property="og:image:height" content="145">






<meta name="twitter:card" content="summary">

<meta name="twitter:title" content="Le B.A.-BA de l‚Äôinf√©rence Bayesienne">

<meta name="twitter:image" content="https://baratin-tools.github.io/img/logo.png">

<meta name="twitter:description" content="">


  </head>

  <body>

    <div id="all">

        


        <header class="navbar-affixed-top" data-spy="affix" data-offset-top="62">
    <div class="navbar navbar-default yamm " role="navigation" id="navbar">
        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="/fr/">
                    
                      <img src="/img/logoWithText.png" alt="Le B.A.-BA de l‚Äôinf√©rence Bayesienne logo" class="hidden-xs hidden-sm" />
                      <img src="/img/logo.png" alt="Le B.A.-BA de l‚Äôinf√©rence Bayesienne logo" class="visible-xs visible-sm" />
                    
                    <span class="sr-only">Le B.A.-BA de l‚Äôinf√©rence Bayesienne - aller √† l&#39;accueil</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Basculer la Navigation</span>
                        <i class="fas fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  

                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/fr">Accueil</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                    
                    
                    <li class="dropdown ">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Documentation <span class="caret"></span></a>
                        
                        <ul class="dropdown-menu">
                            
                            <li><a href="/fr/doc/baratinage">BaRatinAGE</a></li>
                            
                            <li><a href="/fr/doc/topics">Fiches Th√©matiques</a></li>
                            
                            <li><a href="/fr/doc/case">Cas d&#39;√©tude</a></li>
                            
                        </ul>
                        
                    </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/fr/ressources">Ressources</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/fr/blog/">Blog</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/fr/a-propos">A propos</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/fr/index.xml">rss</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/en">üá¨üáß en</a>
                  </li>
                  
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">
                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fas fa-search"></i></button>
                </span>
                    </div>
                </form>
            </div>
            
        </div>
    </div>
</header>




        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Le B.A.-BA de l‚Äôinf√©rence Bayesienne</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-10" id="blog-post">

                        <div id="post-content">
                          

<div id="TOC">
<ul>
<li><a href="#introduction-linf√©rence-statistique" id="toc-introduction-linf√©rence-statistique"><span class="toc-section-number">1</span> Introduction : l‚Äôinf√©rence statistique</a></li>
<li><a href="#la-notion-de-vraisemblance" id="toc-la-notion-de-vraisemblance"><span class="toc-section-number">2</span> La notion de vraisemblance</a>
<ul>
<li><a href="#d√©finition" id="toc-d√©finition"><span class="toc-section-number">2.1</span> D√©finition</a>
<ul>
<li><a href="#variable-al√©atoire-discr√®te" id="toc-variable-al√©atoire-discr√®te"><span class="toc-section-number">2.1.1</span> Variable al√©atoire discr√®te</a></li>
<li><a href="#variable-al√©atoire-continue" id="toc-variable-al√©atoire-continue"><span class="toc-section-number">2.1.2</span> Variable al√©atoire continue</a></li>
</ul></li>
<li><a href="#estimation-par-maximum-de-vraisemblance" id="toc-estimation-par-maximum-de-vraisemblance"><span class="toc-section-number">2.2</span> Estimation par maximum de vraisemblance</a></li>
</ul></li>
<li><a href="#lapproche-bay√©sienne" id="toc-lapproche-bay√©sienne"><span class="toc-section-number">3</span> L‚Äôapproche bay√©sienne</a>
<ul>
<li><a href="#vraisemblance" id="toc-vraisemblance"><span class="toc-section-number">3.1</span> Vraisemblance</a></li>
<li><a href="#distribution-a-priori" id="toc-distribution-a-priori"><span class="toc-section-number">3.2</span> Distribution a priori</a></li>
<li><a href="#distribution-a-posteriori" id="toc-distribution-a-posteriori"><span class="toc-section-number">3.3</span> Distribution a posteriori</a></li>
</ul></li>
</ul>
</div>

<p>L‚Äôobjectif de ce document est de pr√©senter les bases de l‚Äôinf√©rence Bayesienne. Le texte est compl√©t√© par un ensemble de travaux pratiques qui sont t√©l√©chargeables <a href="TP_bayesian.fr.zip">ici</a>.</p>
<div id="introduction-linf√©rence-statistique" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction : l‚Äôinf√©rence statistique</h1>
<p>L‚Äôinf√©rence statistique consiste √† utiliser des donn√©es observ√©es pour estimer certaines propri√©t√©s d‚Äôun mod√®le probabiliste ‚Äì typiquement des param√®tres inconnus que l‚Äôon doit estimer. C‚Äôest un domaine important et vaste des Statistiques. Dans cette fiche, nous nous focalisons sur deux m√©thodes d‚Äôestimation particuli√®res : l‚Äôestimation par maximum de vraisemblance, et surtout l‚Äôestimation bay√©sienne, qui est impl√©ment√©e dans BaRatinAGE.</p>
<p>Le cadre g√©n√©ral est le suivant : on dispose d‚Äôun √©chantillon d‚Äôobservations <span class="math inline">\((y_1,\ldots,y_n)\)</span>, r√©alisations de variables al√©atoires <span class="math inline">\((Y_1,\ldots,Y_n)\)</span>. Nous allons √©mettre une hypoth√®se sur la distribution de <span class="math inline">\((Y_1,\ldots,Y_n)\)</span> : par exemple on supposera que tous les <span class="math inline">\(Y_i\)</span> suivent une loi normale de param√®tres inconnus <span class="math inline">\((\mu,\sigma)\)</span>. L‚Äôobjectif est d‚Äôestimer la valeur des param√®tres <span class="math inline">\((\mu,\sigma)\)</span> √† partir des donn√©es observ√©es <span class="math inline">\((y_1,\ldots,y_n)\)</span>. De mani√®re g√©n√©ral, on d√©signe par <span class="math inline">\(\boldsymbol{\theta}\)</span> le vecteur de param√®tres √† estimer et <span class="math inline">\(f(z;\boldsymbol{\theta})\)</span> la densit√© de la distribution suppos√©e des <span class="math inline">\(Y_i\)</span>. Dans cette notation, <span class="math inline">\(z\)</span> est une valeur quelconque o√π la densit√© est calcul√©e, tandis que la notation ¬´<span class="math inline">\(;\boldsymbol{\theta}\)</span>¬ª vise √† rendre explicite les param√®tres inconnus.</p>
</div>
<div id="la-notion-de-vraisemblance" class="section level1" number="2">
<h1><span class="header-section-number">2</span> La notion de vraisemblance</h1>
<p>Le concept de vraisemblance est central en Statistiques, car il est √† la base de plusieurs m√©thodes d‚Äôestimation, dont l‚Äôestimation bay√©sienne. L‚Äôobjectif de cette section est de d√©finir ce qu‚Äôest une vraisemblance, et de d√©crire la mani√®re pratique de la calculer √† partir d‚Äôun jeu de donn√©es et d‚Äôun mod√®le probabiliste. Nous en profiterons pour d√©crire l‚Äôestimation par maximum de vraisemblance.</p>
<div id="d√©finition" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> D√©finition</h2>
<div id="variable-al√©atoire-discr√®te" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Variable al√©atoire discr√®te</h3>
<p>En termes intuitifs, la vraisemblance est simplement √©gale √† la probabilit√© d‚Äôavoir observ√© les donn√©es d‚Äôapr√®s le mod√®le probabiliste. Consid√©rons par exemple un jeu de pile ou face, pour lequel apr√®s deux lancers successifs, nous obtenons pile puis face. Notons <span class="math inline">\(Y_1\)</span> la variable al√©atoire d√©crivant l‚Äôissue du premier lancer (avec par convention <span class="math inline">\(Y_1=0\)</span> pour pile et <span class="math inline">\(Y_1=1\)</span> pour face), et <span class="math inline">\(Y_2\)</span> la variable al√©atoire d√©crivant l‚Äôissue du second lancer. Les observations peuvent donc √™tre not√©es <span class="math inline">\(\boldsymbol{y}=(y_1,y_2)=(0,1)\)</span>. Si la pi√®ce n‚Äôest pas truqu√©e, les variables al√©atoires <span class="math inline">\(Y_1\)</span> et <span class="math inline">\(Y_2\)</span> suivent une loi de Bernoulli de param√®tre <span class="math inline">\(p=1/2\)</span> : c‚Äôest le modele probabiliste que nous utiliserons. La vraisemblance <span class="math inline">\(V(\boldsymbol{y})\)</span> associ√©e aux donn√©es <span class="math inline">\(\boldsymbol{y}\)</span> est donc √©gale √† :</p>
<p><span class="math display">\[ \begin{align}
V(\boldsymbol{y}) &amp;= Pr(Y_1=y_1 \cap Y_2=y_2)\\
&amp;= Pr(Y_1=0 \cap Y_2=1)\\
&amp;= Pr(Y_1=0) \times Pr( Y_2=1) \text{ (car les lancers sont ind√©pendants)}\\
&amp;= 1/2 \times 1/2 = 1/4
\end{align}
\]</span>
Cette d√©finition intuitive peut √™tre formalis√©e math√©matiquement de la mani√®re suivante. Notons <span class="math inline">\(\boldsymbol{y}=(y_1,\ldots,y_n)\)</span> les donn√©es, et <span class="math inline">\(\boldsymbol{Y}=(Y_1,\ldots,Y_n)\)</span> les variables al√©atoires ayant g√©n√©r√© chaque observation. On suppose que ces variables al√©atoires sont ind√©pendantes deux √† deux. De plus, la fonction de masse de la variable al√©atoire <span class="math inline">\(Y_i\)</span> est not√©e <span class="math inline">\(f_{Y_i}(z)=Pr(Y_i=z)\)</span>. La vraisemblance <span class="math inline">\(V(\boldsymbol{y})\)</span> est alors d√©finie par :</p>
<p><span class="math display">\[V(\boldsymbol{y}) = \prod_{i=1}^{n}{f_{Y_i}(y_i)}\]</span></p>
<p><strong>Remarque 1</strong> : L‚Äôhypoth√®se d‚Äôind√©pendance est importante, en son absence la vraisemblance est plus complexe que le simple produit de l‚Äô√©quation ci-dessus ‚Äì mais nous n‚Äôaborderons pas ce cas de figure ici.</p>
<p><strong>Remarque 2</strong> : Il est fr√©quent de supposer √©galement que les donn√©es sont identiquement distribu√©es, c‚Äôest-√†-dire que toutes les variables al√©atoires ont la m√™me fonction de masse : <span class="math inline">\(f_{Y_1}(z)=f_{Y_2}(z)=\ldots=f_{Y_n}(z)\)</span>. Si l‚Äôon note <span class="math inline">\(f(z)\)</span> cette fonction de masse commune, la vraisemblance s‚Äô√©crit simplement :</p>
<p><span class="math display">\[V(\boldsymbol{y}) = \prod_{i=1}^{n}{f(y_i)}\]</span></p>
<p><strong>Remarque 3</strong> : Lorsque les donn√©es sont suppos√©es ind√©pendantes et identiquement distribu√©es, on utilise l‚Äôacronyme <em>iid</em>.</p>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 1. Calcul d‚Äôune vraisemblance discr√®te</strong></a>. Le fichier de donn√©es contient les occurrences d‚Äôun d√©passement de la crue d√©cennale (ou, pour √™tre plus pr√©cis, de la crue estim√©e comme d√©cennale) : 1 si la crue d√©cennale est d√©pass√©e au cours d‚Äôune ann√©e, 0 sinon. On suppose que ces donn√©es sont <em>iid</em> suivant une distribution de Bernoulli de param√®tre <span class="math inline">\(p=0.1\)</span>. Calculez la vraisemblance, puis recommencez le calcul avec <span class="math inline">\(p=0.3\)</span> et <span class="math inline">\(p=0.5\)</span>. Comment interpr√©tez-vous ces diff√©rentes vraisemblances ?</p>
</blockquote>
</div>
<div id="variable-al√©atoire-continue" class="section level3" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Variable al√©atoire continue</h3>
<p>Dans le cas d‚Äôune variable al√©atoire continue, la d√©finition de la vraisemblance est identique √† celle des equations pr√©c√©dentes pour le cas discret, √† l‚Äôexception du fait que <span class="math inline">\(f_{Y_i}(z)\)</span> d√©signe la densit√© de probabilit√© (au lieu de la fonction de masse dans le cas discret). En termes d‚Äôinterpr√©tation, la vraisemblance n‚Äôest donc plus √©gale √† la probabilit√© d‚Äôavoir observ√© les donn√©es, mais plut√¥t √† la densit√© de probabilit√© des donn√©es. Etant donn√© cette grande similarit√© entre variables discr√®tes et continues, nous nous focaliserons sur les variables continues dans la suite de ce document. Le passage √† une variable discr√®te pourra √™tre fait en rempla√ßant simplement ¬´ densit√© de probabilit√© ¬ª par ¬´ fonction de masse ¬ª.</p>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 2. Calcul d‚Äôune vraisemblance continue</strong></a>. La photo ci-dessous a √©t√© prise √† Sommi√®res, √† proximit√© du Vidourle. Les dates des crues permettent de calculer la dur√©e ayant s√©par√© des √©v√©nements successifs. On suppose que ces dur√©es sont <em>iid</em> suivant une loi exponentielle de param√®tre <span class="math inline">\(\lambda=25\)</span>, dont la densit√© s‚Äô√©crit <span class="math inline">\(f(z)=\frac{e^{-z/\lambda}}{\lambda}\)</span>. Calculez la vraisemblance, puis recommencez le calcul avec <span class="math inline">\(\lambda=10\)</span> et <span class="math inline">\(\lambda=100\)</span>. Comment interpr√©tez-vous ces diff√©rentes vraisemblances ?</p>
</blockquote>
<img src="Vidourles.jpg" width="60%">
<p style="text-align: center;color: gray;">
Marques de crue au d√©tour d‚Äôune rue de Sommi√®res. Cr√©dit photo : Diane Laberge, <a href="http://www.dianelaberge.com/blogue/2012/11/09/laccent-du-sud/">http://www.dianelaberge.com/blogue/2012/11/09/laccent-du-sud/</a>.
</p>
</div>
</div>
<div id="estimation-par-maximum-de-vraisemblance" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Estimation par maximum de vraisemblance</h2>
<p>Le principe de l‚Äôestimation par maximum de vraisemblance appara√Æt intuitivement suite aux TPs propos√©s dans la section pr√©c√©dente : il s‚Äôagit simplement de choisir le param√®tre qui maximise la vraisemblance. Cette approche peut √™tre formalis√©e de la fa√ßon suivante, en reprenant les notations
introduites dans les sections pr√©c√©dentes : les donn√©es sont not√©es <span class="math inline">\(\boldsymbol{y}=(y_1,\ldots,y_n)\)</span>, et <span class="math inline">\(\boldsymbol{Y}=(Y_1,\ldots,Y_n)\)</span> repr√©sentent les variables al√©atoires ayant g√©n√©r√© chaque observation. On suppose √† pr√©sent que la densit√© de probabilit√© de la variable al√©atoire <span class="math inline">\(Y_i\)</span> d√©pend d‚Äôun ou plusieurs param√®tres inconnus, que nous noterons <span class="math inline">\(\boldsymbol{\theta}\)</span>. Cette densit√© peut √™tre not√©e <span class="math inline">\(f_{Y_i}(z;\boldsymbol{\theta})\)</span>. La vraisemblance <span class="math inline">\(V(\boldsymbol{y};\boldsymbol{\theta})\)</span> est alors d√©finie par :</p>
<p><span class="math display">\[V(\boldsymbol{y};\boldsymbol{\theta}) = \prod_{i=1}^{n}{f_{Y_i}(y_i;\boldsymbol{\theta})}\]</span></p>
<p>Tout ce que nous avons r√©alis√© ici est de rendre explicite le vecteur contenant les param√®tres inconnus <span class="math inline">\(\boldsymbol{\theta}\)</span> dans les √©quations. L‚Äôestimateur du maximum de vraisemblance est alors d√©fini comme le vecteur de param√®tre qui maximise la vraisemblance:</p>
<p><span class="math display">\[\hat{\boldsymbol{\theta}} = \mathop{\mathrm{argmax}}_{\boldsymbol{\theta}} V(\boldsymbol{y};\boldsymbol{\theta})\]</span></p>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 3. Estimation par maximum de vraisemblance, cas discret</strong></a>. Reprenez les donn√©es d‚Äôoccurrence du TP 1, et calculez la vraisemblance pour une grille de valeurs du param√®tre <span class="math inline">\(p\)</span>. Tracez la vraisemblance comme une fonction de <span class="math inline">\(p\)</span>, et d√©duisez-en l‚Äôestimateur du maximum de vraisemblance. Quelle autre information utile peut-on tirer de cette fonction de vraisemblance ?</p>
</blockquote>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 4. Estimation par maximum de vraisemblance, cas continu</strong></a>. Reprenez les donn√©es de dur√©e inter-√©v√©nements du TP 2, et calculez la vraisemblance pour une grille de valeurs du param√®tre <span class="math inline">\(\lambda\)</span>. Tracez la vraisemblance comme une fonction de <span class="math inline">\(\lambda\)</span>, et d√©duisez-en l‚Äôestimateur du maximum de vraisemblance. Quelle autre information utile peut-on tirer de cette fonction de vraisemblance ?</p>
</blockquote>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 5. Estimation d‚Äôune r√©gression lin√©aire</strong></a>. Consid√©rons les donn√©es repr√©sent√©es dans la figure ci-dessous, qui correspondent √† des pr√©cipitations (<span class="math inline">\(X\)</span>) et des d√©bits moyens annuels (<span class="math inline">\(Y\)</span>) pour un certain bassin versant. Un lien entre ces deux variables √©tant apparent dans cette figure, on cherche √† √©tablir une relation lin√©aire du type :</p>
</blockquote>
<p><span class="math display">\[y_i=\theta  x_i + \varepsilon_i \text{ avec }  \varepsilon_i \sim \mathcal{N}(0,\sigma)\]</span></p>
<img src="linear.fr.jpg" width="50%">
<p style="text-align: center;color: gray;">
Relation entre la pr√©cipitation annuelle <span class="math inline">\(X\)</span> et le d√©bit annuel <span class="math inline">\(Y\)</span>
</p>
<blockquote>
<p>Cette relation suppose que le d√©bit annuel est √©gal √† une fraction <span class="math inline">\(\theta\)</span> de la pr√©cipitation annuelle, plus un r√©sidu variant d‚Äôann√©e en ann√©e. Ces r√©sidus sont suppos√©es √™tre des r√©alisations d‚Äôune loi normale de moyenne nulle et d‚Äô√©cart-type inconnu <span class="math inline">\(\sigma\)</span>. Sous ces hypoth√®ses, il est possible de montrer que le <span class="math inline">\(i\)</span>e d√©bit annuel est une r√©alisation d‚Äôune loi normale <span class="math inline">\(\mathcal{N}(\theta x_i,\sigma)\)</span> : en d‚Äôautres termes, le mod√®le de r√©gression lin√©aire donne l‚Äôesp√©rance du d√©bit annuel, tandis que l‚Äô√©cart-type des r√©sidus donne l‚Äôincertitude sur le d√©bit annuel qui sera effectivement observ√©. Notez en particulier que les donn√©es <span class="math inline">\(\boldsymbol{y}\)</span> ne sont pas identiquement distribu√©es ici (puisque la moyenne change chaque ann√©e).</p>
</blockquote>
<blockquote>
<ol style="list-style-type: decimal">
<li>Tracez les donn√©es ainsi que la droite de r√©gression pour <span class="math inline">\(\theta=0.1\)</span>.</li>
<li>Calculez la vraisemblance des donn√©es <span class="math inline">\(\boldsymbol{y}\)</span> pour <span class="math inline">\(\theta=0.1\)</span> et <span class="math inline">\(\sigma=50\)</span>.</li>
<li>Recherchez en t√¢tonnant l‚Äôestimateur du maximum de vraisemblance de <span class="math inline">\(\theta\)</span> (on gardera <span class="math inline">\(\sigma=50\)</span>).</li>
<li>Comparez la droite de r√©gression ainsi obtenue avec celle propos√©e par Excel (clic droit‚Ä¶Ajouter une courbe de tendance).</li>
</ol>
</blockquote>
<blockquote>
<p>Remarque : cet exemple, bien qu‚Äôextr√™mement simple, fournit une excellente illustration de l‚Äôestimation des param√®tres d‚Äôun mod√®le d√©terministe. Ici, le mod√®le est la simple relation lin√©aire <span class="math inline">\(y_{sim}=\theta x\)</span>. Le d√©bit <span class="math inline">\(y_{sim}\)</span> est la variable de sortie du mod√®le (aussi appel√© pr√©dictande), la pr√©cipitation <span class="math inline">\(x\)</span> est la variable d‚Äôentr√©e (aussi appel√© pr√©dicteur), et <span class="math inline">\(\theta\)</span> le param√®tre √† estimer. L‚Äôexemple se g√©n√©ralise √† des mod√®les bien plus complexes, et en particulier √† des courbes de tarage !</p>
</blockquote>
</div>
</div>
<div id="lapproche-bay√©sienne" class="section level1" number="3">
<h1><span class="header-section-number">3</span> L‚Äôapproche bay√©sienne</h1>
<p>L‚Äôapproche bay√©sienne est une m√©thode d‚Äôestimation, tout comme la m√©thode du maximum de vraisemblance d√©crite pr√©c√©demment. Certaines de ses propri√©t√©s sont particuli√®rement int√©ressantes dans le contexte hydrologique, notamment en termes de quantification des incertitudes. Nous d√©crivons ici les briques de bases qui composent l‚Äô√©difice bay√©sien : vraisemblance, distribution a priori et distribution a posteriori.</p>
<div id="vraisemblance" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Vraisemblance</h2>
<p>L‚Äôestimation bay√©sienne utilise la vraisemblance telle que d√©finie dans la section pr√©c√©dente. En reprenant
les notations d√©finies pr√©c√©demment, <span class="math inline">\(\boldsymbol{y}=(y_1,\ldots,y_n)\)</span> repr√©sentent les donn√©es et <span class="math inline">\(\boldsymbol{Y}=(Y_1,\ldots,Y_n)\)</span> les variables al√©atoires ayant g√©n√©r√© chaque observation. Dans un contexte bay√©sien, la vraisemblance est not√©e <span class="math inline">\(p(\boldsymbol{y}|\boldsymbol{\theta})\)</span> (plut√¥t que <span class="math inline">\(V(\boldsymbol{y};\boldsymbol{\theta})\)</span>), et nous adopterons donc cette notation dor√©navant :</p>
<p><span class="math display">\[p(\boldsymbol{y}|\boldsymbol{\theta}) = \prod_{i=1}^{n}{f_{Y_i}(y_i;\boldsymbol{\theta})}\]</span></p>
<p>La vraisemblance quantifie l‚Äôinformation port√©e par les donn√©es √† propos des param√®tres inconnus <span class="math inline">\(\boldsymbol{\theta}\)</span>. Cependant, contrairement √† l‚Äôestimation par maximum de vraisemblance, nous ne chercherons pas √† la maximiser ici.</p>
</div>
<div id="distribution-a-priori" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Distribution a priori</h2>
<p>L‚Äôapproche bay√©sienne ne se contente pas d‚Äôutiliser l‚Äôinformation port√©e par les donn√©es : elle permet √©galement d‚Äôint√©grer toute connaissance sur <span class="math inline">\(\boldsymbol{\theta}\)</span> qui serait disponible avant m√™me d‚Äôavoir vu les donn√©es. Cette information est encod√©e sous la forme d‚Äôune distribution, dont la densit√© de probabilit√© est not√©e <span class="math inline">\(p(\boldsymbol{\theta})\)</span>. Comme sugg√©r√© par cette notation, cette distribution ne d√©pend aucunement des donn√©es <span class="math inline">\(\boldsymbol{y}\)</span>. Il s‚Äôagit m√™me l√† d‚Äôune r√®gle d‚Äôor : il est strictement interdit de s‚Äôaider des donn√©es pour sp√©cifier la distribution a priori, car cela reviendrait √† utiliser chaque donn√©e en double, et conduirait √† une forte sous-estimation des incertitudes.</p>
<p>La sp√©cification de la distribution a priori est compl√®tement d√©pendante du contexte, et il n‚Äôexiste donc pas de proc√©dure universelle pour la d√©finir : cette sp√©cification est de la responsabilit√© du mod√©lisateur, qui doit traduire ses connaissances sous la forme d‚Äôune distribution. Ceci introduit in√©vitablement une part de subjectivit√© dans l‚Äôanalyse, ce qui a donn√© lieu √† d‚Äôinterminables d√©bats entre partisans et opposants de l‚Äôapproche bay√©sienne. On peut cependant argumenter que : (1) des calculs totalement objectifs et automatis√©s conduisent parfois √† des r√©sultats extravagants; (2) dans la plupart des analyses de donn√©es, il existe en fait de nombreuses autres √©tapes o√π des choix subjectifs sont faits ; (3) le m√©rite de l‚Äôa priori est de forcer l‚Äôanalyste √† formaliser cette subjectivit√©, et √† la rendre transparente (il faut toujours communiquer l‚Äôa priori que vous avez utilis√© !) ; (4) subjectivit√© et connaissance ne sont pas antinomiques.</p>
<p>Nous verrons des exemples pratiques de sp√©cification des a priori lors des TPs. D‚Äôici l√†, les quelques exemples ci-dessous visent √† illustrer qu‚Äôune connaissance a priori existe souvent en Hydrologie :</p>
<ul>
<li>Consid√©rons le cas de la r√©gression pluie-d√©bit du TP 5 : on peut d√©j√† supposer que <span class="math inline">\(\theta\)</span> est compris entre 0 et 1 (sauf si on soup√ßonne des apports sous-terrain importants d‚Äôun autre bassin versant), et donc le refl√©ter dans l‚Äôa priori (par exemple en sp√©cifiant une distribution a priori uniforme entre 0 et 1). De plus, en fonction de la r√©gion climatique o√π se trouve le bassin versant et de sa taille, on aura vraisemblablement un ordre de grandeur sur la valeur de ce param√®tre, qui repr√©sente un coefficient d‚Äô√©coulement. Par exemple, dans une r√©gion aride ou semi-aride, on serait √©tonn√© de trouver un coefficient de 0.8 pour un bassin naturel de taille moyenne (plus de quelques km¬≤).</li>
<li>Les courbes de tarage fournissent un excellent exemple d‚Äôun cas o√π une connaissance a priori assez forte existe : en effet, les param√®tres d‚Äôune courbe de tarage peuvent √™tre reli√©s √† des propri√©t√©s hydrauliques mesurables (g√©om√©trie de la section ou du chenal, pente, etc.), pour lesquelles une quantification rigoureuse des incertitudes de mesure est possible. C‚Äôest un des principe de base de BaRatin.</li>
<li>Bien qu‚Äôil soit strictement interdit d‚Äôutiliser les donn√©es <span class="math inline">\(\boldsymbol{y}\)</span> pour sp√©cifier la distribution a priori, il n‚Äôest pas interdit d‚Äôen utiliser d‚Äôautres ! Cette id√©e est utilis√©e pour la pr√©d√©termination en utilisant le concept de r√©gionalisation : on utilise des sites ¬´ similaires ¬ª au site cible pour sp√©cifier une distribution a priori ; cette information est alors combin√©e avec les donn√©es du site cible <span class="math inline">\(\boldsymbol{y}\)</span> via une analyse bay√©sienne (voir par exemple <a href="https://hal.inrae.fr/tel-02590034">Ribatet 2007</a>).</li>
</ul>
<p>Pour finir, rappelons que dans le cas g√©n√©ral, <span class="math inline">\(\boldsymbol{\theta}\)</span> est un vecteur (d√®s qu‚Äôil y a plusieurs param√®tres inconnus √† estimer). La distribution a priori est alors multi-dimensionnelle. Une approche fr√©quemment utilis√©e est d‚Äôutiliser des distributions a priori ind√©pendantes sur chaque param√®tre, la distribution sur le vecteur (appel√©e distribution jointe) √©tant alors obtenue par simple multiplication :</p>
<p><span class="math display">\[p(\boldsymbol{\theta})=p(\theta_1,\ldots,\theta_p)=\prod_{i=1}^{p}{p(\theta_i)}\]</span></p>
</div>
<div id="distribution-a-posteriori" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Distribution a posteriori</h2>
<p>Le th√©or√®me de Bayes (image ci-dessous) permet de combiner l‚Äôinformation port√©e par les donn√©es (via la vraisemblance) et l‚Äôinformation a priori en une unique distribution portant sur le vecteur de param√®tres inconnus <span class="math inline">\(\boldsymbol{\theta}\)</span> , nomm√©e distribution a posteriori. La densit√© de probabilit√© a posteriori, not√©e <span class="math inline">\(p(\boldsymbol{\theta}|\boldsymbol{y})\)</span> , est d√©finie par :</p>
<p><span class="math display">\[ p(\boldsymbol{\theta}|\boldsymbol{y}) = \frac{
\overbrace{p(\boldsymbol{y}|\boldsymbol{\theta})}^{\text{vraisemblance}}
\times \overbrace{p(\boldsymbol{\theta})}^{\text{a priori}}
}
{\underbrace{\int p(\boldsymbol{y}|\boldsymbol{\nu}) \times p(\boldsymbol{\nu})d\boldsymbol{\nu}}_{\text{constante de normalisation}}}\]</span></p>
<img src="Thomas_Bayes.gif" width="40%">
<p style="text-align: center;color: gray;">
Thomas Bayes. Source : <a href="https://fr.wikipedia.org/wiki/Thomas_Bayes">Wikipedia</a>
</p>
<p>On voit appara√Ætre au num√©rateur le produit de la vraisemblance et de la densit√© a priori. Le d√©nominateur est plus complexe, puisqu‚Äôil s‚Äôagit d‚Äôint√©grer ce produit par rapport au vecteur de param√®tres. N√©anmoins, on peut remarquer que le d√©nominateur est en fait une constante : les donn√©es <span class="math inline">\(\boldsymbol{y}\)</span> sont fix√©es, et le param√®tre <span class="math inline">\(\boldsymbol{\nu}\)</span> disparait puisqu‚Äôil s‚Äôagit de la variable d‚Äôint√©gration. Cette constante est en fait une simple constante de normalisation : elle permet d‚Äôassurer que l‚Äôaire sous la densit√© a posteriori vaut 1 (ce qui, rappelons-le, est une propri√©t√© n√©cessaire de toute densit√©). Il se trouve qu‚Äôil n‚Äôest pas n√©cessaire de calculer cette constante en pratique (nous verrons pourquoi dans la page sur les <a href="/fr/doc/topics/mcmc">m√©thodes MCMC</a>). Ceci permet de simplifier la pr√©sentation du th√©or√®me de Bayes de la mani√®re suivante :</p>
<p><span class="math display">\[ p(\boldsymbol{\theta}|\boldsymbol{y}) \propto p(\boldsymbol{y}|\boldsymbol{\theta}) p(\boldsymbol{\theta})\]</span></p>
<p>o√π le symbole ¬´ <span class="math inline">\(\propto\)</span> ¬ª signifie ¬´ est proportionnel √†‚Ä¶ ¬ª. Cette √©quation montre que l‚Äôobtention de la densit√© a posteriori (√† une constante pr√®s) est d‚Äôune simplicit√© absolue : il suffit de multiplier la vraisemblance par la densit√© a priori. Le r√©sultat quantifie la connaissance sur les param√®tres <span class="math inline">\(\boldsymbol{\theta}\)</span>, √©tant donn√© les deux sources d‚Äôinformation que sont les donn√©es et la connaissance a priori.</p>
<p>Il est int√©ressant de noter que le r√©sultat brut d‚Äôune estimation bay√©sienne est une distribution. A titre de comparaison, le r√©sultat brut des autres m√©thodes d‚Äôestimation (moments, maximum de vraisemblance, etc.) est un nombre. Cette observation appelle les remarques suivantes :</p>
<ul>
<li>Le r√©sultat brut de l‚Äôestimation bay√©sienne fournit directement une incertitude.</li>
<li>Ceci ne signifie pas qu‚Äôil est impossible de quantifier l‚Äôincertitude avec les autres m√©thodes d‚Äôestimation : en fait, elles poss√®dent toutes une th√©orie solide et bien d√©velopp√©e √† cet effet. Mais cette quantification se fait seulement dans un second temps, apr√®s avoir estim√© une valeur.</li>
<li>Inversement, ceci ne signifie pas non plus qu‚Äôil est impossible d‚Äôobtenir une valeur estim√©e avec l‚Äôapproche bay√©sienne : typiquement, le maximum de la densit√© a posteriori est couramment utilis√© √† cet effet. C‚Äôest en quelque sorte l‚Äô√©quivalent bay√©sien du maximum de vraisemblance. On appellera cet estimateur l‚Äôestimateur Maxpost (¬´ estimateur MAP ¬ª est √©galement utilis√© pour Maximum A Posteriori).</li>
</ul>
<p>Les remarques ci-dessus montrent que toutes les m√©thodes d‚Äôestimation peuvent fournir une estimation ponctuelle (i.e.¬†une valeur) ainsi qu‚Äôune incertitude. Les bay√©siens convaincus pr√©tendront n√©anmoins que la quantification de l‚Äôincertitude est plus naturelle dans le cadre bay√©sien, car l‚Äôincertitude est le r√©sultat brut, et l‚Äôestimation ponctuelle le produit d√©riv√© (alors que c‚Äôest l‚Äôinverse avec les autres m√©thodes d‚Äôestimation).</p>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 6. Estimation bay√©sienne, cas discret</strong></a>. Reprenez les calculs effectu√©s dans le TP 3 et compl√©tez-les pour effectuer une analyse bay√©sienne compl√®te. Ceci implique de : (1) sp√©cifier une densit√© a priori ; (2) calculer la densit√© a posteriori. Tracez la vraisemblance, la densit√© a priori et la densit√© a posteriori et comparez-les.</p>
</blockquote>
<blockquote>
<p>La personne ayant effectu√© le calcul de la crue d√©cennale vous informe qu‚Äôelle n‚Äôa pas utilis√© vos donn√©es pour faire ce calcul. De plus, elle a effectu√© une analyse d‚Äôincertitude et d‚Äôapr√®s cette analyse, l‚Äôincertitude sur la probabilit√© de d√©passement peut-√™tre repr√©sent√©e par une loi log-normale <span class="math inline">\(Log\mathcal{N}(\mu=log(0.1),\sigma=0.75)\)</span>. Tirez parti de cette information.</p>
</blockquote>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 7. Estimation bay√©sienne, cas continu</strong></a>. Reprenez les calculs effectu√©s dans le TP 4 et compl√©tez-les pour effectuer une analyse bay√©sienne compl√®te.
De plus, un coll√®gue hydrologue-hydraulicien vous informe que d‚Äôapr√®s son estimation, la p√©riode de retour
avec laquelle ce coin de rue est inond√© est comprise dans l‚Äôintervalle [10 ans; 100 ans] √† un niveau de
confiance 95%. Tirez parti de cette information.</p>
</blockquote>
<blockquote>
<p><a href="TP_bayesian.fr.zip"><strong>TP 8. Estimation bay√©sienne d‚Äôune r√©gression lin√©aire</strong></a>. Reprenez les calculs effectu√©s dans le TP 5 et compl√©tez-les pour effectuer une estimation bay√©sienne du param√®tre <span class="math inline">\(\theta\)</span> (on supposera <span class="math inline">\(\sigma=50\)</span> connu). Tracez la vraisemblance, la densit√© a priori et la densit√© a posteriori. Relancez les calculs en choisissant d‚Äôautres valeurs pour <span class="math inline">\(\sigma\)</span>, et commentez les r√©sultats.</p>
</blockquote>
</div>
</div>


                        </div>                        
                        
  <div class="container">
    
    

    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/analyse-hydraulique/">L&#39;analyse hydraulique</a> 
		

		
		    &nbsp; | &nbsp;
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/controles-hydrauliques/">Contr√¥les hydrauliques</a> 
		

		
		    &nbsp; | &nbsp;
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/jaugeages/">Incertitudes sur les jaugeages</a> 
		

		
		    &nbsp; | &nbsp;
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/courbe-de-tarage/">Equation de la courbe de tarage</a> 
		

		
		    &nbsp; | &nbsp;
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/limni/">Incertitudes dans les limnigrammes</a> 
		

		
		    &nbsp; | &nbsp;
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/modele-stat/">Mod√®le statistique</a> 
		

		
		    &nbsp; | &nbsp;
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/hydrogrammes/">Incertitudes dans les hydrogrammes</a> 
		

		
		    &nbsp; | &nbsp;
		
    
		
		   <strong> <a href="https://baratin-tools.github.io/fr/doc/topics/bayesien/">Le B.A.-BA de l‚Äôinf√©rence Bayesienne</a> </strong> 

		

		
		    &nbsp; | &nbsp;
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/mcmc/">Algorithmes MCMC</a> 
		

		
    
         
  
  </div>
    




                    </div>
                    

                    

                    

                    <div class="col-md-2">

                        
                    
                        
  <div class="container">
  	<h3> Sections </h3>
    
    
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/analyse-hydraulique/">L&#39;analyse hydraulique</a> </br> </br>
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/controles-hydrauliques/">Contr√¥les hydrauliques</a> </br> </br>
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/jaugeages/">Incertitudes sur les jaugeages</a> </br> </br>
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/courbe-de-tarage/">Equation de la courbe de tarage</a> </br> </br>
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/limni/">Incertitudes dans les limnigrammes</a> </br> </br>
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/modele-stat/">Mod√®le statistique</a> </br> </br>
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/hydrogrammes/">Incertitudes dans les hydrogrammes</a> </br> </br>
		
    
		
		<div style="background-color:beige;">
		   <strong> <a href="https://baratin-tools.github.io/fr/doc/topics/bayesien/">Le B.A.-BA de l‚Äôinf√©rence Bayesienne</a> </strong></br>
		</div>
		</br>
		
    
		
		    <a href="https://baratin-tools.github.io/fr/doc/topics/mcmc/">Algorithmes MCMC</a> </br> </br>
		
    
         
  
  </div>
    





                        

                    </div>
                    

                    

                </div>
                

            </div>
            
            
            
        </div>
        

        <footer id="footer">
  <div class="container">
    
  
  </div>
    
</footer>




    </div>
    

    
<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>


<script src="/js/front.js"></script>



  </body>
</html>
